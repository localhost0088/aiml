{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#BFS\n",
        "from collections import deque\n",
        "\n",
        "def bfs(graph, start):\n",
        "    visited = set()\n",
        "    queue = deque([start])\n",
        "    final_sequence = []\n",
        "\n",
        "    while queue:\n",
        "        node = queue.popleft()\n",
        "        print(f\"Popped: {node}\")\n",
        "\n",
        "        if node not in visited:\n",
        "            final_sequence.append(node)\n",
        "            visited.add(node)\n",
        "            print(f\"Added to final sequence: {node}\")\n",
        "\n",
        "            for neighbor in graph[node]:\n",
        "                if neighbor not in visited:\n",
        "                    queue.append(neighbor)\n",
        "                    print(f\"Added to queue: {neighbor}\")\n",
        "\n",
        "    print(\"\\nFinal BFS sequence:\", \" \".join(final_sequence))\n",
        "\n",
        "\n",
        "graph = {\n",
        "    'A': ['B', 'C'],\n",
        "    'B': ['D', 'E'],\n",
        "    'C': ['F'],\n",
        "    'D': [],\n",
        "    'E': ['F'],\n",
        "    'F': []\n",
        "}\n",
        "\n",
        "bfs(graph, 'A')\n"
      ],
      "metadata": {
        "id": "zSa3xeGKA8vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DFS\n",
        "def dfs(graph, start):\n",
        "    visited = set()\n",
        "    stack = [start]\n",
        "    final_sequence = []\n",
        "\n",
        "    while stack:\n",
        "        node = stack.pop()\n",
        "        print(f\"Popped: {node}\")\n",
        "\n",
        "        if node not in visited:\n",
        "            final_sequence.append(node)\n",
        "            visited.add(node)\n",
        "            print(f\"Added to final sequence: {node}\")\n",
        "\n",
        "            for neighbor in reversed(graph[node]):\n",
        "                if neighbor not in visited:\n",
        "                    stack.append(neighbor)\n",
        "                    print(f\"Added to stack: {neighbor}\")\n",
        "\n",
        "    print(\"\\nFinal DFS sequence:\", \" \".join(final_sequence))\n",
        "\n",
        "graph = {\n",
        "    'A': ['B', 'C'],\n",
        "    'B': ['D', 'E'],\n",
        "    'C': ['F'],\n",
        "    'D': [],\n",
        "    'E': ['F'],\n",
        "    'F': []\n",
        "}\n",
        "\n",
        "dfs(graph, 'A')\n"
      ],
      "metadata": {
        "id": "JuovLQsADTog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Water Jug Problem\n",
        "from collections import deque\n",
        "\n",
        "def water_jug_solver(CA, CB, T):\n",
        "\n",
        "    path = []\n",
        "    visited = set()\n",
        "    q = deque([(0, 0, None, None)])\n",
        "\n",
        "    while q:\n",
        "        a, b, prev_action, from_jug = q.popleft()\n",
        "\n",
        "        if (a, b) in visited:\n",
        "            continue\n",
        "\n",
        "        visited.add((a, b))\n",
        "        path.append((prev_action, from_jug, None, a, b))\n",
        "\n",
        "        if a == T or b == T:\n",
        "            return path\n",
        "\n",
        "        q.append((CA, b, \"Fill\", \"A\"))\n",
        "        q.append((a, CB, \"Fill\", \"B\"))\n",
        "        q.append((0, b, \"Empty\", \"A\"))\n",
        "        q.append((a, 0, \"Empty\", \"B\"))\n",
        "\n",
        "        pour_into_B = min(a, CB - b)\n",
        "        q.append((a - pour_into_B, b + pour_into_B, \"Pour\", \"A\"))\n",
        "\n",
        "        pour_into_A = min(b, CA - a)\n",
        "        q.append((a + pour_into_A, b - pour_into_A, \"Pour\", \"B\"))\n",
        "\n",
        "    return \"No solution found.\"\n",
        "\n",
        "CA = 4\n",
        "CB = 3\n",
        "T = 2\n",
        "\n",
        "result = water_jug_solver(CA, CB, T)\n",
        "\n",
        "if result == \"No solution found.\":\n",
        "    print(result)\n",
        "else:\n",
        "    print(\"Steps to reach the target volume:\")\n",
        "    for step in result:\n",
        "        action, from_jug, to_jug, a, b = step\n",
        "        if action == \"Fill\":\n",
        "            print(f\"Fill {from_jug} jug. Jug A: {a}, Jug B: {b}\")\n",
        "        elif action == \"Empty\":\n",
        "            print(f\"Empty {from_jug} jug. Jug A: {a}, Jug B: {b}\")\n",
        "        elif action == \"Pour\":\n",
        "            print(f\"Pour water from {from_jug} jug to B jug. Jug A: {a}, Jug B: {b}\")\n",
        "        else:\n",
        "            print(f\"Initial state. Jug A: {a}, Jug B: {b}\")"
      ],
      "metadata": {
        "id": "sMRzLLPPHdnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best first search\n",
        "from queue import PriorityQueue\n",
        "\n",
        "def best_first_search(graph, start, goal):\n",
        "    visited = set()\n",
        "    pq = PriorityQueue()\n",
        "    pq.put((0, start))\n",
        "    print(f\"Initial state: Priority Queue: {pq.queue}\")\n",
        "\n",
        "    while not pq.empty():\n",
        "        priority, current_node = pq.get()\n",
        "        if current_node in visited:\n",
        "            continue\n",
        "\n",
        "        visited.add(current_node)\n",
        "        print(f\"Current Node: {current_node}, Visited: {visited}, Priority Queue: {pq.queue}\")\n",
        "\n",
        "        if current_node == goal:\n",
        "            print(\"\\nGoal reached!\")\n",
        "            return\n",
        "\n",
        "        for neighbor, cost in graph[current_node]:\n",
        "            if neighbor not in visited:\n",
        "                pq.put((cost, neighbor))\n",
        "                print(f\"Added {neighbor} to Priority Queue: {pq.queue}\")\n",
        "\n",
        "    print(\"\\nGoal not reachable.\")\n",
        "    return\n",
        "\n",
        "# Example graph\n",
        "graph = {\n",
        "    'A': [('B', 1), ('C', 4), ('D', 3)],\n",
        "    'B': [('E', 4)],\n",
        "    'C': [('E', 2), ('F', 5)],\n",
        "    'D': [('F', 6)],\n",
        "    'E': [('G', 2)],\n",
        "    'F': [('G', 1)],\n",
        "    'G': []\n",
        "}\n",
        "\n",
        "start = 'A'\n",
        "goal = 'G'\n",
        "print(f\"Best First Search starting from {start} to {goal}:\")\n",
        "best_first_search(graph, start, goal)"
      ],
      "metadata": {
        "id": "1zgEmtGPUstW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Missionaries and Cannibals\n",
        "def is_valid(state):\n",
        "    m_left, c_left, boat, m_right, c_right = state\n",
        "    if m_left < 0 or c_left < 0 or m_right < 0 or c_right < 0:\n",
        "        return False\n",
        "    if m_left > 0 and m_left < c_left:\n",
        "        return False\n",
        "    if m_right > 0 and m_right < c_right:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def get_successors(state):\n",
        "    m_left, c_left, boat, m_right, c_right = state\n",
        "    successors = []\n",
        "    if boat == 'left':\n",
        "        moves = [(-2, 0), (0, -2), (-1, -1), (-1, 0), (0, -1)]\n",
        "    else:\n",
        "        moves = [(2, 0), (0, 2), (1, 1), (1, 0), (0, 1)]\n",
        "\n",
        "    for m_move, c_move in moves:\n",
        "        new_state = (m_left + m_move, c_left + c_move, 'right' if boat == 'left' else 'left',m_right - m_move, c_right - c_move)\n",
        "        if is_valid(new_state):\n",
        "            successors.append(new_state)\n",
        "    return successors\n",
        "\n",
        "def bfs(start_state, goal_state):\n",
        "    queue = [(start_state, [start_state])]\n",
        "    while queue:\n",
        "        current_state, path = queue.pop(0)\n",
        "        if current_state == goal_state:\n",
        "            return path\n",
        "        for successor in get_successors(current_state):\n",
        "            if successor not in path:\n",
        "                queue.append((successor, path + [successor]))\n",
        "    return None\n",
        "\n",
        "start_state = (3, 3, 'left', 0, 0)\n",
        "goal_state = (0, 0, 'right', 3, 3)\n",
        "solution = bfs(start_state, goal_state)\n",
        "\n",
        "if solution:\n",
        "    print(\"Solution found:\")\n",
        "    for step in solution:\n",
        "        print(step)\n",
        "else:\n",
        "    print(\"No solution found.\")\n"
      ],
      "metadata": {
        "id": "VCqf7Hi9U0wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A*\n",
        "\n",
        "from heapq import heappop, heappush\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, value, g=0, h=0):\n",
        "        self.value = value\n",
        "        self.g = g\n",
        "        self.h = h\n",
        "        self.f = g + h\n",
        "\n",
        "def a_star(graph, start, goal, heuristic):\n",
        "    open_list = [(start.f, start)]\n",
        "    closed_list = set()\n",
        "\n",
        "    while open_list:\n",
        "        current_f, current = heappop(open_list)\n",
        "        print(f\"OPEN: {[n.value for _, n in open_list]}, Visiting: {current.value}\")\n",
        "\n",
        "        if current.value == goal:\n",
        "            return f\"Goal node {goal} found!\"\n",
        "\n",
        "        closed_list.add(current.value)\n",
        "\n",
        "        for neighbor, cost in graph[current.value].items():\n",
        "            if neighbor in closed_list:\n",
        "                continue\n",
        "\n",
        "            g = current.g + cost\n",
        "            h = heuristic[neighbor]\n",
        "            neighbor_node = Node(neighbor, g, h)\n",
        "\n",
        "            if not any(n.value == neighbor and n.f <= neighbor_node.f for _, n in open_list):\n",
        "                heappush(open_list, (neighbor_node.f, neighbor_node))\n",
        "\n",
        "        if not open_list:\n",
        "            return f\"Goal node {goal} not found!\"\n",
        "\n",
        "    return f\"Goal node {goal} not found!\"\n",
        "\n",
        "graph = {'A': {'B': 1, 'C': 4}, 'B': {'D': 1, 'E': 4}, 'C': {'F': 5}, 'D': {}, 'E': {}, 'F': {}}\n",
        "heuristic = {'A': 7, 'B': 6, 'C': 2, 'D': 1, 'E': 6, 'F': 0}\n",
        "\n",
        "start_node = Node('A', 0, heuristic['A'])\n",
        "\n",
        "goal_node_value = 'F'\n",
        "\n",
        "result = a_star(graph, start_node, goal_node_value, heuristic)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN3mWjGmU6kX",
        "outputId": "99715ad2-8074-44fa-814d-2edd282a1059"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPEN: [], Visiting: A\n",
            "OPEN: ['B'], Visiting: C\n",
            "OPEN: ['F'], Visiting: B\n",
            "OPEN: ['F', 'E'], Visiting: D\n",
            "OPEN: ['E'], Visiting: F\n",
            "Goal node F found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aStv8dRWU9UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1 scatter plot on iris\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "iris_data = pd.read_csv(\"/home/fymsc8/MLDatasets/Iris.csv\")\n",
        "print(iris_data.head())\n",
        "x = iris_data['SepalLengthCm']\n",
        "y = iris_data['SepalWidthCm']\n",
        "species = iris_data['Species']\n",
        "plt.figure(figsize=(10, 6))\n",
        "for sp in species.unique():\n",
        "    sp_data = iris_data[species == sp]\n",
        "    plt.scatter(sp_data['SepalLengthCm'], sp_data['SepalWidthCm'], label=sp)\n",
        "plt.title('Scatter Plot of Iris Dataset')\n",
        "plt.xlabel('Sepal Length (cm)')\n",
        "plt.ylabel('Sepal Width (cm)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ss0rHIlVVLTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2 find null values and replace with mean\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "iris_data = pd.read_csv(\"/home/fymsc8/MLDatasets/Iris.csv\")\n",
        "print(\"Original Data:\")\n",
        "print(iris_data.head())\n",
        "print(\"\\nNull values in each column before imputation:\")\n",
        "print(iris_data.isnull().sum())\n",
        "\n",
        "total_null_values = iris_data.isnull().sum().sum()\n",
        "print(\"\\nTotal number of null values in the dataset:\", total_null_values)\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "iris_data_imputed = pd.DataFrame(imputer.fit_transform(iris_data.iloc[:, :-1]), columns=iris_data.columns[:-1])\n",
        "iris_data_imputed['Species'] = iris_data['Species']\n",
        "print(\"\\nData after imputation:\")\n",
        "print(iris_data_imputed.head())\n",
        "print(\"\\nNull values in each column after imputation:\")\n",
        "print(iris_data_imputed.isnull().sum())\n"
      ],
      "metadata": {
        "id": "Ub3volyxWDDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3 convert categorical values to numeric format in a given dataset using label encoding and one hot encoder\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "iris_data = pd.read_csv(\"/home/fymsc8/MLDatasets/Iris.csv\")\n",
        "print(\"Original Data:\")\n",
        "print(iris_data.head())\n",
        "label_encoder = LabelEncoder()\n",
        "iris_data['Species_Label'] = label_encoder.fit_transform(iris_data['Species'])\n",
        "print(\"\\nData with Label Encoded Species:\")\n",
        "print(iris_data.head())\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "species_onehot = onehot_encoder.fit_transform(iris_data[['Species']])\n",
        "species_onehot_df = pd.DataFrame(species_onehot, columns=onehot_encoder.get_feature_names_out(['Species']))\n",
        "iris_data = pd.concat([iris_data, species_onehot_df], axis=1)\n",
        "print(\"\\nData with One-Hot Encoded Species:\")\n",
        "print(iris_data.head())\n"
      ],
      "metadata": {
        "id": "LBSJOdf8WFbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4 scale values\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "salary_data = pd.read_csv(\"/home/fymsc8/MLDatasets/Salary_Data.csv\")\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(salary_data.head())\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "salary_data[['Salary']] = imputer.fit_transform(salary_data[['Salary']])\n",
        "\n",
        "categorical_columns = salary_data.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_columns:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    salary_data[col] = label_encoders[col].fit_transform(salary_data[col])\n",
        "\n",
        "features = salary_data.drop('Salary', axis=1)\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "scaled_features_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
        "\n",
        "scaled_salary_data = pd.concat([scaled_features_df, salary_data['Salary']], axis=1)\n",
        "\n",
        "print(\"\\nScaled Data:\")\n",
        "print(scaled_salary_data.head())\n"
      ],
      "metadata": {
        "id": "hhFLJdJWWHpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set B\n",
        "#1 split data into training and test set\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "iris_data = pd.read_csv(\"/home/fymsc8/MLDatasets/Iris.csv\")\n",
        "print(\"Original Data:\")\n",
        "print(iris_data.head())\n",
        "X = iris_data.drop('Species', axis=1)\n",
        "y = iris_data['Species']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"\\nTraining set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
        "print(\"\\nTraining set:\")\n",
        "print(X_train.head(), y_train.head())\n",
        "print(\"\\nTest set:\")\n",
        "print(X_test.head(), y_test.head())\n"
      ],
      "metadata": {
        "id": "D5VzlPWhWJ-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set B\n",
        "# 2 scale features using standardization\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "data = pd.read_csv(\"/home/fymsc8/MLDatasets/Dataset7.csv\")\n",
        "print(\"Original Data:\")\n",
        "print(data.head())\n",
        "features = data.drop('Target', axis=1, errors='ignore')\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "scaled_features_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
        "if 'Target' in data.columns:\n",
        "    scaled_data = pd.concat([scaled_features_df, data['Target']], axis=1)\n",
        "else:\n",
        "    scaled_data = scaled_features_df\n",
        "print(\"Scaled Data:\")\n",
        "print(scaled_data.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "wW2_pKgKWMGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQM8r7psWOQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SetA\n",
        "#Q1 i simple linear regression\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/home/fymsc8/MLDatasets/House_price_prediction.csv')\n",
        "\n",
        "X = dataset['sqft_living'].values.reshape(-1, 1)\n",
        "y = dataset['price'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R^2 Score:\", r2)\n",
        "\n",
        "plt.scatter(X_train, y_train, color='blue')\n",
        "plt.plot(X_train, model.predict(X_train), color='red')\n",
        "plt.title('House Price Prediction (Training set)')\n",
        "plt.xlabel('sqft_living')\n",
        "plt.ylabel('Price')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(X_test, y_test, color='blue')\n",
        "plt.plot(X_train, model.predict(X_train), color='red')\n",
        "plt.title('House Price Prediction (Test set)')\n",
        "plt.xlabel('sqft_living')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9097LzAaWWNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1\n",
        "# ii multiple linear regression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/home/fymsc8/MLDatasets/House_price_prediction.csv')\n",
        "\n",
        "X = dataset[['yr_built', 'floors', 'sqft_living']].values\n",
        "y = dataset['price'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R^2 Score:\", r2)\n",
        "\n",
        "plt.scatter(y_test, y_pred, color='blue')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')\n",
        "plt.title('House Price Prediction (Test set)')\n",
        "plt.xlabel('Actual Price')\n",
        "plt.ylabel('Predicted Price')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Mmmyel4LYxTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2 polynomial regression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/home/fymsc8/MLDatasets/Position_Salaries1.csv\")\n",
        "\n",
        "X = data.iloc[:, 1:2].values\n",
        "y = data.iloc[:, 2].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "poly_reg = PolynomialFeatures(degree=4)\n",
        "X_poly = poly_reg.fit_transform(X)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_poly, y)\n",
        "\n",
        "plt.scatter(X, y, color='red')\n",
        "plt.plot(X, lin_reg.predict(poly_reg.fit_transform(X)), color='blue')\n",
        "plt.title('Polynomial Regression')\n",
        "plt.xlabel('Position level')\n",
        "plt.ylabel('Salary')\n",
        "plt.show()\n",
        "\n",
        "position_level = 6.5\n",
        "salary_pred = lin_reg.predict(poly_reg.fit_transform([[position_level]]))\n",
        "print(\"Predicted Salary for Position Level {}: ${}\".format(position_level, salary_pred[0]))\n",
        "\n",
        "y_pred = lin_reg.predict(poly_reg.fit_transform(X_test))\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "id": "VWjH2AfUYzZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3 decision tree regression and support vector regression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv(\"/home/fymsc8/MLDatasets/Position_Salaries1.csv\")\n",
        "\n",
        "X = dataset.iloc[:, 1:2].values\n",
        "y = dataset.iloc[:, 2].values\n",
        "\n",
        "sc_X = StandardScaler()\n",
        "sc_y = StandardScaler()\n",
        "X = sc_X.fit_transform(X)\n",
        "y = sc_y.fit_transform(y.reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "regressor_dt = DecisionTreeRegressor(random_state=0)\n",
        "regressor_dt.fit(X, y)\n",
        "\n",
        "regressor_svr = SVR(kernel='poly')\n",
        "regressor_svr.fit(X, y)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plot_tree(regressor_dt, filled=True, feature_names=['Position level'], fontsize=10)\n",
        "plt.title('Decision Tree Structure')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='red')\n",
        "plt.plot(X, regressor_svr.predict(X), color='blue')\n",
        "plt.title('SVR with Polynomial Kernel')\n",
        "plt.xlabel('Position level')\n",
        "plt.ylabel('Salary')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Dnm5WluY1u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set B\n",
        "#Q1 simple linear regression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv(\"/home/fymsc8/MLDatasets/StudentHoursScores.csv\")\n",
        "\n",
        "X = dataset['Hours'].values.reshape(-1, 1)\n",
        "y = dataset['Scores'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R^2 Score:\", r2)\n",
        "\n",
        "plt.scatter(X_test, y_test, color='blue')\n",
        "plt.plot(X_test, y_pred, color='red')\n",
        "plt.title('Student Scores vs Study Hours')\n",
        "plt.xlabel('Study Hours')\n",
        "plt.ylabel('Scores')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SqYvnEnHY4RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set B\n",
        "# Q2 prediction model using multiple linear regression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/home/fymsc8/MLDatasets/50_Startups.csv')\n",
        "\n",
        "X = dataset[['Administration', 'State', 'Marketing Spend', 'R&D Spend']]\n",
        "y = dataset['Profit']\n",
        "\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R^2 Score:\", r2)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.scatter(y_test, y_pred, color='blue')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
        "\n",
        "plt.title('Actual vs Predicted Profit')\n",
        "plt.xlabel('Actual Profit')\n",
        "plt.ylabel('Predicted Profit')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RzN33U7jY6yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3\n",
        "# 1 linear regression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "dataset = pd.read_csv('/home/fymsc8/MLDatasets/Position_Salaries1.csv')\n",
        "\n",
        "X = dataset.iloc[:, 1:2].values\n",
        "y = dataset.iloc[:, 2].values\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='blue', label='Actual Data')\n",
        "plt.plot(X, y_pred, color='red', label='Regression Line')\n",
        "plt.title('Simple Linear Regression Fit')\n",
        "plt.xlabel('Position Level')\n",
        "plt.ylabel('Salary')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v3NEpCEaY83h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2 polynomial regression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/home/fymsc8/MLDatasets/Position_Salaries1.csv')\n",
        "\n",
        "X = dataset.iloc[:, 1:2].values\n",
        "y = dataset.iloc[:, 2].values\n",
        "\n",
        "poly_reg = PolynomialFeatures(degree=4)\n",
        "X_poly = poly_reg.fit_transform(X)\n",
        "\n",
        "model_poly = LinearRegression()\n",
        "model_poly.fit(X_poly, y)\n",
        "\n",
        "y_pred_poly = model_poly.predict(X_poly)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='blue', label='Actual Data')\n",
        "plt.plot(X, y_pred_poly, color='red', label='Polynomial Regression Line')\n",
        "plt.title('Polynomial Regression Fit')\n",
        "plt.xlabel('Position Level')\n",
        "plt.ylabel('Salary')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "quCK35JxY-_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "olf1U8EcbIZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set A\n",
        "#Q1(1) GaussianNB\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/home/fymsc8/Ass4_MLDatasets/Social_Network_Ads.csv\")\n",
        "\n",
        "print(df)\n",
        "\n",
        "X = df.iloc[:, [2, 3]].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Accuracy:\", accuracy*100,\"%\")\n",
        "\n",
        "print(f\"Correctly predicted 'Not Purchased': {cm[0][0]}\")\n",
        "print(f\"Correctly predicted 'Purchased': {cm[1][1]}\")\n",
        "print(f\"Incorrectly predicted as 'Purchased' when they weren't: {cm[0][1]}\")\n",
        "print(f\"Incorrectly predicted as 'Not Purchased' when they were: {cm[1][0]}\")\n",
        "\n",
        "def plot_decision_boundary(X, y, model, title):\n",
        "    from matplotlib.colors import ListedColormap\n",
        "    X_set, y_set = X, y\n",
        "    X1, X2 = np.meshgrid(np.arange(X_set[:, 0].min() - 1, X_set[:, 0].max() + 1, 0.01),\n",
        "                         np.arange(X_set[:, 1].min() - 1, X_set[:, 1].max() + 1, 0.01))\n",
        "    plt.contourf(X1, X2, model.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "                 alpha=0.75, cmap=ListedColormap(('red', 'blue')))\n",
        "    plt.xlim(X1.min(), X1.max())\n",
        "    plt.ylim(X2.min(), X2.max())\n",
        "    for i, j in enumerate(np.unique(y_set)):\n",
        "        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                    c=[ListedColormap(('red', 'blue'))(i)], label=j)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Age')\n",
        "    plt.ylabel('Estimated Salary')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(X_train, y_train, classifier, 'Naïve Bayes (Training set)')\n",
        "\n",
        "plot_decision_boundary(X_test, y_test, classifier, 'Naïve Bayes (Test set)')\n"
      ],
      "metadata": {
        "id": "cdlnMH7WbJ8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set A\n",
        "#Q1(1) Bernoulli\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, Binarizer\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/home/fymsc8/Ass4_MLDatasets/Social_Network_Ads.csv\")\n",
        "\n",
        "X = df.iloc[:, [2, 3]].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "binarizer = Binarizer(threshold=0.0)\n",
        "X_train_binarized = binarizer.fit_transform(X_train)\n",
        "X_test_binarized = binarizer.transform(X_test)\n",
        "\n",
        "classifier = BernoulliNB()\n",
        "classifier.fit(X_train_binarized, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test_binarized)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Accuracy:\", accuracy*100, \"%\")\n",
        "\n",
        "print(f\"Correctly predicted 'Not Purchased': {cm[0][0]}\")\n",
        "print(f\"Correctly predicted 'Purchased': {cm[1][1]}\")\n",
        "print(f\"Incorrectly predicted as 'Purchased' when they weren't: {cm[0][1]}\")\n",
        "print(f\"Incorrectly predicted as 'Not Purchased' when they were: {cm[1][0]}\")\n",
        "\n",
        "def plot_decision_boundary(X, y, model, title):\n",
        "    from matplotlib.colors import ListedColormap\n",
        "    X_set, y_set = X, y\n",
        "    X1, X2 = np.meshgrid(np.arange(X_set[:, 0].min() - 1, X_set[:, 0].max() + 1, 0.01),\n",
        "                         np.arange(X_set[:, 1].min() - 1, X_set[:, 1].max() + 1, 0.01))\n",
        "    plt.contourf(X1, X2, model.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "                 alpha=0.75, cmap=ListedColormap(('red', 'blue')))\n",
        "    plt.xlim(X1.min(), X1.max())\n",
        "    plt.ylim(X2.min(), X2.max())\n",
        "    for i, j in enumerate(np.unique(y_set)):\n",
        "        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                    c=[ListedColormap(('red', 'blue'))(i)], label=j)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Age')\n",
        "    plt.ylabel('Estimated Salary')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(X_train_binarized, y_train, classifier, 'Bernoulli Naïve Bayes (Training set)')\n",
        "\n",
        "plot_decision_boundary(X_test_binarized, y_test, classifier, 'Bernoulli Naïve Bayes (Test set)')\n"
      ],
      "metadata": {
        "id": "WaHkHvdobKuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set A\n",
        "#Q1(1) Multinomial\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/home/fymsc8/Ass4_MLDatasets/Social_Network_Ads.csv\")\n",
        "\n",
        "X = df.iloc[:, [2, 3]].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
        "X_train_binned = discretizer.fit_transform(X_train)\n",
        "X_test_binned = discretizer.transform(X_test)\n",
        "\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_binned, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test_binned)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Accuracy:\", accuracy * 100, \"%\")\n",
        "\n",
        "print(f\"Correctly predicted 'Not Purchased': {cm[0][0]}\")\n",
        "print(f\"Correctly predicted 'Purchased': {cm[1][1]}\")\n",
        "print(f\"Incorrectly predicted as 'Purchased' when they weren't: {cm[0][1]}\")\n",
        "print(f\"Incorrectly predicted as 'Not Purchased' when they were: {cm[1][0]}\")\n",
        "\n",
        "def plot_decision_boundary(X, y, model, title):\n",
        "    from matplotlib.colors import ListedColormap\n",
        "    X_set, y_set = X, y\n",
        "    X1, X2 = np.meshgrid(np.arange(X_set[:, 0].min() - 1, X_set[:, 0].max() + 1, 0.1),\n",
        "                         np.arange(X_set[:, 1].min() - 1, X_set[:, 1].max() + 1, 0.1))\n",
        "    plt.contourf(X1, X2, model.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "                 alpha=0.75, cmap=ListedColormap(('red', 'blue')))\n",
        "    plt.xlim(X1.min(), X1.max())\n",
        "    plt.ylim(X2.min(), X2.max())\n",
        "    for i, j in enumerate(np.unique(y_set)):\n",
        "        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                    c=[ListedColormap(('red', 'blue'))(i)], label=j)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Age')\n",
        "    plt.ylabel('Estimated Salary')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(X_train_binned, y_train, classifier, 'Multinomial Naïve Bayes (Training set)')\n",
        "\n",
        "plot_decision_boundary(X_test_binned, y_test, classifier, 'Multinomial Naïve Bayes (Test set)')\n"
      ],
      "metadata": {
        "id": "jnzlfRRobMs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set A\n",
        "#Q1(2) random forest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "df = pd.read_csv(\"/home/fymsc8/Ass4_MLDatasets/Social_Network_Ads.csv\")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "X = df.iloc[:, [2, 3]].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Accuracy:\", accuracy*100,\"%\")\n",
        "\n",
        "print(f\"Correctly predicted 'Not Purchased': {cm[0][0]}\")\n",
        "print(f\"Correctly predicted 'Purchased': {cm[1][1]}\")\n",
        "print(f\"Incorrectly predicted as 'Purchased' when they weren't: {cm[0][1]}\")\n",
        "print(f\"Incorrectly predicted as 'Not Purchased' when they were: {cm[1][0]}\")\n"
      ],
      "metadata": {
        "id": "Fx6ZYUEpbO9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set A\n",
        "#Q1(3) kernel svm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "df = pd.read_csv(\"/home/fymsc8/Ass4_MLDatasets/Social_Network_Ads.csv\")\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "X = df.iloc[:, [2, 3]].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "classifier = SVC(kernel='rbf', random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Accuracy:\", accuracy*100,\"%\")\n",
        "\n",
        "print(f\"Correctly predicted 'Not Purchased': {cm[0][0]}\")\n",
        "print(f\"Correctly predicted 'Purchased': {cm[1][1]}\")\n",
        "print(f\"Incorrectly predicted as 'Purchased' when they weren't: {cm[0][1]}\")\n",
        "print(f\"Incorrectly predicted as 'Not Purchased' when they were: {cm[1][0]}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zAQszJUdbQ_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tennis\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/home/fymsc8/Ass4_MLDatasets/Tennis.csv\")\n",
        "print(df)\n",
        "\n",
        "df.rename(columns={\"Play Tennis\": \"PlayTennis\"}, inplace=True)\n",
        "\n",
        "label_encoders = {}\n",
        "for column in df.columns[:-1]:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "target_encoder = LabelEncoder()\n",
        "df[\"PlayTennis\"] = target_encoder.fit_transform(df[\"PlayTennis\"])\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "classifier = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nAccuracy:\", round(accuracy * 100, 2), \"%\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plot_tree(classifier, feature_names=X.columns, class_names=target_encoder.classes_, filled=True)\n",
        "plt.title(\"Decision Tree for Playing Tennis\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "K9lJrHFYbS3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask questions based on the dataset columns\n",
        "def get_user_input():\n",
        "    print(\"\\nAnswer the following questions to predict whether to play tennis or not:\")\n",
        "    outlook = input(\"Outlook (Sunny/Overcast/Rainy): \").capitalize()\n",
        "    temperature = input(\"Temperature (Hot/Mild/Cool): \").capitalize()\n",
        "    humidity = input(\"Humidity (High/Low): \").capitalize()\n",
        "    wind = input(\"Wind (Weak/Strong): \").capitalize()\n",
        "\n",
        "    try:\n",
        "        outlook_encoded = label_encoders['Outlook'].transform([outlook])[0]\n",
        "        temperature_encoded = label_encoders['Temperature'].transform([temperature])[0]\n",
        "        humidity_encoded = label_encoders['Humidity'].transform([humidity])[0]\n",
        "        wind_encoded = label_encoders['Wind'].transform([wind])[0]\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Please ensure the values are correct (e.g., 'Sunny', 'Hot', 'High', 'Weak').\")\n",
        "        return None\n",
        "\n",
        "    return [outlook_encoded, temperature_encoded, humidity_encoded, wind_encoded]\n",
        "\n",
        "user_input = get_user_input()\n",
        "if user_input:\n",
        "    user_input_df = pd.DataFrame([user_input], columns=X.columns)\n",
        "\n",
        "    prediction = classifier.predict(user_input_df)\n",
        "    prediction_label = target_encoder.inverse_transform(prediction)\n",
        "\n",
        "    print(f\"\\nPrediction: {'Play' if prediction_label[0] == 1 else 'play'} tennis.\")\n"
      ],
      "metadata": {
        "id": "nkRs3DlFbUqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set A\n",
        "#Q3 k-nearest neighbour\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv(\"/home/fymsc8/Ass4_MLDatasets/Social_Network_Ads.csv\")\n",
        "print(dataset)\n",
        "\n",
        "X = dataset.iloc[:, [2, 3]].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy*100,\"%\")\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Accuracy:\", accuracy*100,\"%\")\n",
        "\n",
        "def plot_decision_boundary(X_set, y_set, model, title):\n",
        "    from matplotlib.colors import ListedColormap\n",
        "    X1, X2 = np.meshgrid(np.arange(start=X_set[:, 0].min()-1, stop=X_set[:, 0].max()+1, step=0.01),\n",
        "                         np.arange(start=X_set[:, 1].min()-1, stop=X_set[:, 1].max()+1, step=0.01))\n",
        "\n",
        "    plt.contourf(X1, X2, model.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "                 alpha=0.5, cmap=ListedColormap(('red', 'green')))\n",
        "\n",
        "    plt.scatter(X_set[:, 0], X_set[:, 1], c=y_set, cmap=ListedColormap(('red', 'green')))\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Age')\n",
        "    plt.ylabel('Estimated Salary')\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(X_train, y_train, knn, \"KNN Decision Boundary (Training Set)\")\n",
        "\n",
        "plot_decision_boundary(X_test, y_test, knn, \"KNN Decision Boundary (Test Set)\")\n"
      ],
      "metadata": {
        "id": "QAs7U82fbWmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set B\n",
        "#Q1 k-nearest neighbour suv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv(\"/home/fymsc8/Ass4_MLDatasets/User_Data.csv\")\n",
        "\n",
        "X = dataset.iloc[:, [2, 3]].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Performance:\")\n",
        "print(f\"Accuracy: \",accuracy*100,\"%\")\n",
        "print(f\"Precision: \",precision*100,\"%\")\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "X_set, y_set = X_test, y_test\n",
        "X1, X2 = np.meshgrid(np.arange(start=X_set[:, 0].min() - 1, stop=X_set[:, 0].max() + 1, step=0.01),\n",
        "                     np.arange(start=X_set[:, 1].min() - 1, stop=X_set[:, 1].max() + 1, step=0.01))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.contourf(X1, X2, knn.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "             alpha=0.75, cmap=ListedColormap(('blue', 'red')))\n",
        "\n",
        "plt.scatter(X_set[:, 0], X_set[:, 1], c=y_set, cmap=ListedColormap(('blue', 'red')), edgecolors='k')\n",
        "plt.title(\"K-Nearest Neighbors Classification\")\n",
        "plt.xlabel(\"Age (Scaled)\")\n",
        "plt.ylabel(\"Estimated Salary (Scaled)\")\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RlOzOz9wbYj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age = int(input(\"Enter Age: \"))\n",
        "salary = int(input(\"Enter Estimated Salary: \"))\n",
        "\n",
        "user_data = scaler.transform([[age, salary]])\n",
        "\n",
        "prediction = knn.predict(user_data)\n",
        "\n",
        "if prediction[0] == 1:\n",
        "    print(\"\\nPrediction: YES! The person is likely to buy an SUV \")\n",
        "else:\n",
        "    print(\"\\nPrediction: NO! The person is NOT likely to buy an SUV\")\n"
      ],
      "metadata": {
        "id": "RfrwuHmubalQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iuEOC8dpbcYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set A\n",
        "#Q1 k-means\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def generate_data(n_samples=300, random_state=42):\n",
        "    X, y = make_blobs(n_samples=n_samples, n_features=6, centers=3, random_state=random_state)\n",
        "    scaler = MinMaxScaler(feature_range=(10, 150))\n",
        "    X = scaler.fit_transform(X)\n",
        "    df = pd.DataFrame(X, columns=[\"Annual_Income\", \"Spending_Score\", \"Age\", \"Savings\", \"Debt\", \"Credit_Score\"])\n",
        "    df[\"Customer_Segment\"] = y\n",
        "    return df\n",
        "\n",
        "def apply_kmeans(X, n_clusters=3):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    kmeans.fit(X)\n",
        "    return kmeans.labels_, kmeans.cluster_centers_\n",
        "\n",
        "def plot_clusters(X, labels, centers):\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', marker='o', edgecolors='k')\n",
        "    plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='X', s=200, label='Centroids')\n",
        "    plt.title('Customer Segmentation using K-Means')\n",
        "    plt.xlabel('Annual Income (in $1000s)')\n",
        "    plt.ylabel('Spending Score')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "dataset = generate_data()\n",
        "print(dataset.head())\n",
        "\n",
        "labels, centers = apply_kmeans(dataset.iloc[:, :-1].values)\n",
        "\n",
        "plot_clusters(dataset.iloc[:, [0, 1]].values, labels, centers[:, :2])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k7ZcEioQbcUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set A\n",
        "#Q2 agglomerative clustering\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "def generate_data(n_samples=1000, random_state=42):\n",
        "    X, y = make_blobs(n_samples=n_samples, n_features=6, centers=3, random_state=random_state)\n",
        "    scaler = MinMaxScaler(feature_range=(10, 15))\n",
        "    X = scaler.fit_transform(X)\n",
        "    df = pd.DataFrame(X, columns=[\"Annual_Income\", \"Spending_Score\", \"Age\", \"Savings\", \"Debt\", \"Credit_Score\"])\n",
        "    df[\"Customer_Segment\"] = y\n",
        "    return df\n",
        "\n",
        "def apply_agglomerative_clustering(X, n_clusters=3):\n",
        "    agglo = AgglomerativeClustering(n_clusters=n_clusters)\n",
        "    labels = agglo.fit_predict(X)\n",
        "    return labels\n",
        "\n",
        "def plot_clusters(X, labels):\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', marker='o', edgecolors='k')\n",
        "    plt.title('Customer Segmentation using Agglomerative Clustering')\n",
        "    plt.xlabel('Annual Income (in $1000s)')\n",
        "    plt.ylabel('Spending Score')\n",
        "    plt.show()\n",
        "\n",
        "def plot_dendrogram(X):\n",
        "    linked = linkage(X, method='ward')\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    dendrogram(linked)\n",
        "    plt.title('Hierarchical Clustering Dendrogram')\n",
        "    plt.xlabel('Data Points')\n",
        "    plt.ylabel('Euclidean Distance')\n",
        "    plt.show()\n",
        "\n",
        "dataset = generate_data()\n",
        "print(dataset.head())\n",
        "\n",
        "labels_agglo = apply_agglomerative_clustering(dataset.iloc[:, :-1].values)\n",
        "plot_clusters(dataset.iloc[:, [0, 1]].values, labels_agglo)\n",
        "\n",
        "plot_dendrogram(dataset.iloc[:, :-1].values)\n"
      ],
      "metadata": {
        "id": "-2dNh54WdMVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set B\n",
        "#Q1 optimal no of clusters using elbow and apply k-means\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "df = pd.read_csv(\"/home/fymsc8/MLDatasets/Mall_Customers.csv\")\n",
        "print(df.head())\n",
        "\n",
        "X = df.iloc[:, [3, 4]].values\n",
        "\n",
        "wcss = []\n",
        "for k in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"WCSS (Within-Cluster Sum of Squares)\")\n",
        "plt.title(\"Elbow Method for Optimal k\")\n",
        "plt.show()\n",
        "\n",
        "optimal_k = np.argmax(np.diff(wcss, 2)) + 2\n",
        "print(f\"The optimal number of clusters is: {optimal_k}\")\n",
        "\n",
        "optimal_k = 3\n",
        "\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df[\"Cluster\"] = kmeans.fit_predict(X)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "for i in range(optimal_k):\n",
        "    plt.scatter(X[df[\"Cluster\"] == i, 0], X[df[\"Cluster\"] == i, 1], label=f'Cluster {i}')\n",
        "\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', marker='X', label='Centroids')\n",
        "plt.xlabel(\"Annual Income (k$)\")\n",
        "plt.ylabel(\"Spending Score (1-100)\")\n",
        "plt.title(\"Customer Segmentation using K-Means\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gdY1JzdLdOSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set B\n",
        "#Q2 agglomerative clustering and show clusters\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "df = pd.read_csv(\"/home/fymsc8/MLDatasets/penguins.csv\")\n",
        "print(df.head())\n",
        "\n",
        "df_filtered = df[['flipper_length_mm', 'body_mass_g']].dropna().copy()\n",
        "X = df_filtered.values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "linked = linkage(X_scaled, method='ward')\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "dendrogram(linked)\n",
        "plt.title('Dendrogram for Agglomerative Clustering')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Euclidean Distance')\n",
        "plt.show()\n",
        "\n",
        "threshold = 8\n",
        "\n",
        "clusters = fcluster(linked, threshold, criterion='distance')\n",
        "\n",
        "optimal_clusters = len(np.unique(clusters))\n",
        "print(f\"The optimal number of clusters is: {optimal_clusters}\")\n",
        "\n",
        "agglo = AgglomerativeClustering(n_clusters=optimal_clusters)\n",
        "df_filtered[\"clusters\"] = agglo.fit_predict(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "for cluster in range(optimal_clusters):\n",
        "    plt.scatter(X[df_filtered[\"clusters\"] == cluster, 0],\n",
        "                X[df_filtered[\"clusters\"] == cluster, 1], label=f'Cluster {cluster}')\n",
        "\n",
        "plt.xlabel(\"Flipper Length (mm)\")\n",
        "plt.ylabel(\"Body Mass (g)\")\n",
        "plt.title(\"Penguin Clusters using Agglomerative Clustering\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WRoqJhhWdQUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apriori\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "np.random.seed(42)\n",
        "items = [\"Milk\", \"Bread\", \"Butter\", \"Cheese\", \"Eggs\", \"Fruits\", \"Vegetables\"]\n",
        "n_transactions = 100\n",
        "\n",
        "data = np.random.choice([True, False], size=(n_transactions, len(items)), p=[0.4, 0.6])\n",
        "df = pd.DataFrame(data, columns=items)\n",
        "\n",
        "frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
        "\n",
        "print(\"\\nGenerated Basket Data:\\n\", df.head())\n",
        "print(\"\\nFrequent Itemsets:\\n\", frequent_itemsets)\n",
        "print(\"\\nAssociation Rules:\\n\", rules)\n",
        "\n",
        "item1 = input(\"Enter first item: \")\n",
        "item2 = input(\"Enter second item: \")\n",
        "\n",
        "if {item1, item2}.issubset(set(df.columns)):\n",
        "    total_transactions = len(df)\n",
        "    both_chosen = df[(df[item1] == True) & (df[item2] == True)].shape[0]\n",
        "    probability = both_chosen / total_transactions\n",
        "    print(f\"\\nProbability of both {item1} and {item2} being chosen together: {probability:.2f}\")\n",
        "else:\n",
        "    print(\"\\nInvalid items entered! Please choose from:\", items)\n"
      ],
      "metadata": {
        "id": "ae0s9TAYdSpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fpgrowth\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
        "\n",
        "np.random.seed(42)\n",
        "items = [\"Milk\", \"Bread\", \"Butter\", \"Cheese\", \"Eggs\", \"Fruits\", \"Vegetables\"]\n",
        "n_transactions = 100\n",
        "\n",
        "data = np.random.choice([True, False], size=(n_transactions, len(items)), p=[0.4, 0.6])\n",
        "df = pd.DataFrame(data, columns=items)\n",
        "\n",
        "frequent_itemsets = fpgrowth(df, min_support=0.2, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
        "\n",
        "print(\"\\nGenerated Basket Data:\\n\", df.head())\n",
        "print(\"\\nFrequent Itemsets:\\n\", frequent_itemsets)\n",
        "print(\"\\nAssociation Rules:\\n\", rules)\n",
        "\n",
        "import random\n",
        "\n",
        "items = [\"Milk\", \"Bread\", \"Butter\", \"Cheese\", \"Eggs\", \"Fruits\", \"Vegetables\"]\n",
        "n_transactions = 100\n",
        "\n",
        "transactions = []\n",
        "for _ in range(n_transactions):\n",
        "    transaction = random.sample(items, random.randint(1, len(items)))\n",
        "    transactions.append(transaction)\n",
        "\n",
        "print(\"Generated Transactions:\")\n",
        "for transaction in transactions[:5]:\n",
        "    print(transaction)\n"
      ],
      "metadata": {
        "id": "DMBaACG9dVEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eclat\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "items = [\"Milk\", \"Bread\", \"Butter\", \"Cheese\", \"Eggs\"]\n",
        "n_transactions = 20\n",
        "\n",
        "transactions = []\n",
        "for _ in range(n_transactions):\n",
        "    transaction = random.sample(items, random.randint(1, len(items)))\n",
        "    transactions.append(transaction)\n",
        "\n",
        "print(\"Generated Transactions:\")\n",
        "for transaction in transactions[:5]:\n",
        "    print(transaction)\n",
        "\n",
        "def eclat_low_memory(transactions, min_support):\n",
        "    item_to_transactions = defaultdict(set)\n",
        "\n",
        "    for idx, transaction in enumerate(transactions):\n",
        "        for item in transaction:\n",
        "            item_to_transactions[item].add(idx)\n",
        "\n",
        "    frequent_itemsets = []\n",
        "    for item, trans_ids in item_to_transactions.items():\n",
        "        if len(trans_ids) >= min_support:\n",
        "            frequent_itemsets.append((frozenset([item]), trans_ids))\n",
        "\n",
        "    result = []\n",
        "    k = 2\n",
        "    while frequent_itemsets:\n",
        "        next_itemsets = []\n",
        "        for i in range(len(frequent_itemsets)):\n",
        "            for j in range(i + 1, len(frequent_itemsets)):\n",
        "                itemset1, trans_ids1 = frequent_itemsets[i]\n",
        "                itemset2, trans_ids2 = frequent_itemsets[j]\n",
        "\n",
        "                new_itemset = itemset1.union(itemset2)\n",
        "                if len(new_itemset) == k:\n",
        "                    new_trans_ids = trans_ids1.intersection(trans_ids2)\n",
        "                    if len(new_trans_ids) >= min_support:\n",
        "                        next_itemsets.append((new_itemset, new_trans_ids))\n",
        "\n",
        "        result.extend(next_itemsets)\n",
        "        frequent_itemsets = next_itemsets\n",
        "        k += 1\n",
        "\n",
        "    return result\n",
        "\n",
        "min_support = 5\n",
        "\n",
        "frequent_itemsets = eclat_low_memory(transactions, min_support)\n",
        "\n",
        "print(\"\\nFrequent Itemsets (min_support={}):\".format(min_support))\n",
        "for itemset, trans_ids in frequent_itemsets:\n",
        "    print(f\"{set(itemset)}: {len(trans_ids)} transactions\")\n"
      ],
      "metadata": {
        "id": "OH6_wqsadXVh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}